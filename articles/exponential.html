<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="series.system.estimation.masked.data">
<title>Series system with exponentially distributed component lifetimes • series.system.estimation.masked.data</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Series system with exponentially distributed component lifetimes">
<meta property="og:description" content="series.system.estimation.masked.data">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">series.system.estimation.masked.data</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/exponential.html">Series system with exponentially distributed component lifetimes</a>
    <a class="dropdown-item" href="../articles/weibull.html">weibull</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="exponential_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Series system with exponentially distributed component lifetimes</h1>
            
      
      
      <div class="d-none name"><code>exponential.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://queelius.github.io/series_system_estimation_masked_data/">series.system.estimation.masked.data</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/queelius/algebraic.mle" class="external-link">algebraic.mle</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://queelius.github.io/md.tools/" class="external-link">md.tools</a></span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: 'md.tools'</span>
<span class="co">#&gt; The following object is masked from 'package:series.system.estimation.masked.data':</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     exp_series_md_1</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span>
<span class="co">#&gt; ── <span style="font-weight: bold;">Attaching packages</span> ─────────────────────────────────────── tidyverse 1.3.1 ──</span>
<span class="co">#&gt; <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">ggplot2</span> 3.3.6     <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">purrr  </span> 0.3.4</span>
<span class="co">#&gt; <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">tibble </span> 3.1.7     <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">dplyr  </span> 1.0.9</span>
<span class="co">#&gt; <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">tidyr  </span> 1.2.0     <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">stringr</span> 1.4.0</span>
<span class="co">#&gt; <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">readr  </span> 2.1.2     <span style="color: #00BB00;">✔</span> <span style="color: #0000BB;">forcats</span> 0.5.1</span>
<span class="co">#&gt; ── <span style="font-weight: bold;">Conflicts</span> ────────────────────────────────────────── tidyverse_conflicts() ──</span>
<span class="co">#&gt; <span style="color: #BB0000;">✖</span> <span style="color: #0000BB;">dplyr</span>::<span style="color: #00BB00;">filter()</span> masks <span style="color: #0000BB;">stats</span>::filter()</span>
<span class="co">#&gt; <span style="color: #BB0000;">✖</span> <span style="color: #0000BB;">dplyr</span>::<span style="color: #00BB00;">lag()</span>    masks <span style="color: #0000BB;">stats</span>::lag()</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://devtools.r-lib.org/" class="external-link">devtools</a></span><span class="op">)</span>
<span class="co">#&gt; Loading required package: usethis</span>
<span class="co">#devtools::install_github("queelius/algebraic.mle")</span>
<span class="co">#devtools::install_github("queelius/md.tools")</span></code></pre></div>

<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The R package <code>series.system.estimation.masked.data</code> is a framework for estimating the parameters of latent component lifetimes from <em>masked data</em> in a series system.</p>
</div>
<div class="section level2">
<h2 id="masked-data">Masked data<a class="anchor" aria-label="anchor" href="#masked-data"></a>
</h2>
<p>Masked data is given by an i.i.d. sample of system lifetime data and <em>plausible</em> candidate sets that contain the failed node.</p>
<p>The R package <code>series.system.estimation.masked.data</code> contains several simulated masked data sets. For example, a series system with <span class="math inline">\(3\)</span> exponentially distributed component lifetimes is stored in <code>exp_series_data_1</code>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">exp_series_md_1</span><span class="op">)</span>
<span class="co">#&gt; Latent variables:  k t1 t2 t3 </span>
<span class="co">#&gt; <span style="color: #949494;"># A tibble: 1,000 × 8</span></span>
<span class="co">#&gt;          t     k      t1      t2     t3 x1    x2    x3   </span>
<span class="co">#&gt;      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 0.144       2 0.281   0.144   0.266  TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 0.010<span style="text-decoration: underline;">5</span>      1 0.010<span style="text-decoration: underline;">5</span>  0.014<span style="text-decoration: underline;">1</span>  0.063<span style="text-decoration: underline;">3</span> TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 0.036<span style="text-decoration: underline;">3</span>      2 0.105   0.036<span style="text-decoration: underline;">3</span>  0.545  TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 0.009<span style="text-decoration: underline;">72</span>     1 0.009<span style="text-decoration: underline;">72</span> 0.251   0.096<span style="text-decoration: underline;">0</span> TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 0.037<span style="text-decoration: underline;">7</span>      3 0.093<span style="text-decoration: underline;">7</span>  0.094<span style="text-decoration: underline;">3</span>  0.037<span style="text-decoration: underline;">7</span> TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 0.095<span style="text-decoration: underline;">8</span>      3 0.283   0.391   0.095<span style="text-decoration: underline;">8</span> FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 0.169       3 0.197   1.01    0.169  FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 0.270       3 0.322   0.371   0.270  FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 0.299       3 0.390   0.401   0.299  TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 0.007<span style="text-decoration: underline;">94</span>     2 0.524   0.007<span style="text-decoration: underline;">94</span> 0.120  FALSE TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #949494;"># … with 990 more rows</span></span></code></pre></div>
<p>You can get help on any object in <code>series.system.estimation.masked.data</code> using the built-in help. For instance, to get information on the data set <code>exp_series_md_1</code>, type <code><a href="../reference/exp_series_md_1.html">?exp_series_md_1</a></code> in your R console.</p>
</div>
<div class="section level2">
<h2 id="statistical-model-for-masked-data">Statistical model for masked data<a class="anchor" aria-label="anchor" href="#statistical-model-for-masked-data"></a>
</h2>
<p>The principle object of study is the series system consisting of <span class="math inline">\(m\)</span> components. We are interested in estimating the component lifetimes from masked data in the form of candidate sets, where the candidate sets satisfy the following set of conditions:</p>
<ul>
<li><p>Condition <span class="math inline">\(C_1\)</span>: The index of the failed component is in the candidate set, i.e., <span class="math inline">\(\Pr\{K_i \in C_i\} = 1\)</span>.</p></li>
<li><p>Condition <span class="math inline">\(C_2\)</span>: The probability of <span class="math inline">\(C_i\)</span> given <span class="math inline">\(K_i\)</span> and <span class="math inline">\(T_i\)</span> is equally probable when the failed component varies over the components in the candidate set, i.e., <span class="math inline">\(\Pr\{C_i=c_i|K_i=j,T_i=t_i\} = \Pr\{C_i=c_i|K_i=j',T_i=t_i\}\)</span> for any <span class="math inline">\(j,j' \in c_i\)</span>.</p></li>
<li>
<p>Condition <span class="math inline">\(C_3\)</span>: The masking probabilities are independent of <span class="math inline">\(\boldsymbol{\theta}\)</span>, i.e., <span class="math inline">\(\Pr\{C_i=c_i|K_i=j,T_i=t_i\}\)</span> is not a function of <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<p>That means, whatever the generative mechanism underlying <span class="math inline">\(\mathcal{C}_1,\ldots,\mathcal{C}_n\)</span>, it has no explicit knowledge of <span class="math inline">\(\boldsymbol{\theta}\)</span>, but the <span class="math inline">\(i\)</span> candidate set <span class="math inline">\(\mathcal{C}_i\)</span> may depend on the realizations of <span class="math inline">\(T_{i 1},\ldots,T_{i n}\)</span> and other factors not explicitly in the statistical model we have described.</p>
</li>
</ul>
<div class="section level3">
<h3 id="bernoulli-candidate-model-that-satisfies-c_1-c_2-and-c_3">Bernoulli candidate model that satisfies <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span><a class="anchor" aria-label="anchor" href="#bernoulli-candidate-model-that-satisfies-c_1-c_2-and-c_3"></a>
</h3>
<p>As long as we satisfy conditions <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span>, our reduced likelihood function that assumes those conditions obtains the same MLEs as the full likelihood function.</p>
<p>In what follows, we describe our Bernoulli candidate set model that generates candidate sets that satisfy these conditions.</p>
<div class="r-help-page">
<div class="container">
<table width="100%" class="table"><tr>
<td>
md_bernoulli_candidate_C1_C2_C3
</td>
<td style="text-align: right;">
R Documentation
</td>
</tr></table>
<h3>
Bernoulli candidate model that is a function of component cause of failure.
</h3>
<h4>
Description
</h4>
<p>
Bernoulli candidate model that is a function of component cause of failure <code>k</code> and parameters <code>m</code> and <code>p</code>, where if component cause of failure is indexed by <code>j</code>, then <code>j</code> is in the candidate set and otherwise the component indexed by <code>j</code> is in the candidate set with probability specified by <code>p</code>, which may either by a procedure for sampling from a distribution with a codomain <code>[0,1]</code> or a constant function.
</p>
<h4>
Usage
</h4>
<pre class="r"><code class="language-R"><span class="fu"><a href="../reference/md_bernoulli_candidate_C1_C2_C3.html">md_bernoulli_candidate_C1_C2_C3</a></span><span class="op">(</span><span class="va">md</span>, <span class="va">m</span>, p <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></code></pre>
<h4>
Arguments
</h4>
<table class="table">
<tr valign="top">
<td>
<code>md</code>
</td>
<td>
<p>
masked data, has a column <code>k</code> for the failed component index.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>m</code>
</td>
<td>
<p>
integer, number of components in the candidate set.
</p>
</td>
</tr>
<tr valign="top">
<td>
<code>p</code>
</td>
<td>
<p>
a function or procedure <code>p : integer -&gt; [0,1]</code>, defaults to <code>function(n) runif(n)</code>.
</p>
</td>
</tr>
</table>
</div>
</div>
<pre><code><span class="co">#&gt; function (md, m, p = function(n) runif(n)) </span>
<span class="co">#&gt; {</span>
<span class="co">#&gt;     stopifnot(!is.null(md$k))</span>
<span class="co">#&gt;     n &lt;- nrow(md)</span>
<span class="co">#&gt;     stopifnot(n &gt; 0)</span>
<span class="co">#&gt;     x &lt;- matrix(NA, nrow = n, ncol = m)</span>
<span class="co">#&gt;     u &lt;- matrix(runif(m * n), nrow = n)</span>
<span class="co">#&gt;     gam &lt;- p(n)</span>
<span class="co">#&gt;     for (i in 1:n) {</span>
<span class="co">#&gt;         for (j in 1:m) {</span>
<span class="co">#&gt;             x[i, j] &lt;- ifelse(md$k[i] == j, T, u[i, j] &lt; gam[i])</span>
<span class="co">#&gt;         }</span>
<span class="co">#&gt;     }</span>
<span class="co">#&gt;     x &lt;- tibble::as_tibble(x)</span>
<span class="co">#&gt;     colnames(x) &lt;- paste0("x", 1:m)</span>
<span class="co">#&gt;     md %&gt;% dplyr::bind_cols(x)</span>
<span class="co">#&gt; }</span>
<span class="co">#&gt; &lt;bytecode: 0x563521aa1068&gt;</span>
<span class="co">#&gt; &lt;environment: namespace:series.system.estimation.masked.data&gt;</span></code></pre>
</div>
<div class="section level3">
<h3 id="estimating-the-variance-covariance-using-the-bootstrap-method">Estimating the variance-covariance using the Bootstrap method<a class="anchor" aria-label="anchor" href="#estimating-the-variance-covariance-using-the-bootstrap-method"></a>
</h3>
<p>Alternatively, we could estimate <span class="math inline">\(\boldsymbol{\theta}\)</span> with <span class="math inline">\(B\)</span> simulated draws from the MLEs that satisfy <span class="math display">\[
    \operatorname{argmax}_{\boldsymbol{\theta }\in \boldsymbol{\Omega}} \ell(\boldsymbol{\theta}|\mathcal{D_i})
\]</span> where <span class="math inline">\(\mathcal{\boldsymbol{D_i}}\)</span> is a random sample from the empirical distribution <span class="math inline">\(\{(S_i,\delta_i,C_i)\}_1^n\)</span>. We call this the <em>Bootstrap</em>.</p>
<p>Assuming the above solution to the MLE equation is <em>unique</em>, this gives us a single point <span class="math inline">\(\hat{\boldsymbol{\theta}}_{(i)}\)</span> when conditioned on the simulated masked data <span class="math inline">\(\boldsymbol{D_i}\)</span>.</p>
</div>
</div>
<div class="section level2">
<h2 id="exponential-series-system">Exponential series system<a class="anchor" aria-label="anchor" href="#exponential-series-system"></a>
</h2>
<p>The most straightforward series system to estimate is the series system with exponentially distributed component lifetimes.</p>
<p>Suppose an exponential series system with <span class="math inline">\(m\)</span> components is parameterized by <span class="math inline">\(\boldsymbol{\theta }= (3,4,5)'\)</span>. Then, the component assigned to index <span class="math inline">\(j\)</span> has an exponentially distributed lifetime with a failure rate <span class="math inline">\(\theta_j\)</span>, e.g., <span class="math inline">\(\theta_2 = 4\)</span> is the failure rate of the component indexed by <span class="math inline">\(4\)</span>.</p>
<p>Let’s simulate a series system (without candidate sets):</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">300</span>
<span class="co">#theta &lt;- c(3,4,5)</span>
<span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">3</span>,<span class="fl">3</span><span class="op">)</span>
<span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>

<span class="va">md</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>t1<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,
             t2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,
             t3<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="../reference/md_series_lifetime.html">md_series_lifetime</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">md</span><span class="op">)</span>
<span class="co">#&gt; <span style="color: #949494;"># A tibble: 300 × 5</span></span>
<span class="co">#&gt;        t1    t2     t3     k      t</span>
<span class="co">#&gt;     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 0.046<span style="text-decoration: underline;">5</span> 0.321 0.170      1 0.046<span style="text-decoration: underline;">5</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 1.03   0.678 0.205      3 0.205 </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 0.604  0.200 0.627      2 0.200 </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 0.090<span style="text-decoration: underline;">3</span> 1.08  0.320      1 0.090<span style="text-decoration: underline;">3</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 0.150  0.210 0.415      1 0.150 </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 0.224  0.188 0.439      2 0.188 </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 0.717  0.468 0.035<span style="text-decoration: underline;">1</span>     3 0.035<span style="text-decoration: underline;">1</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 0.099<span style="text-decoration: underline;">6</span> 0.136 0.116      1 0.099<span style="text-decoration: underline;">6</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 0.284  0.223 0.107      3 0.107 </span>
<span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 0.118  0.654 1.07       1 0.118 </span>
<span class="co">#&gt; <span style="color: #949494;"># … with 290 more rows</span></span></code></pre></div>
<p>In the above, we used the function <code>md_series_lifetime</code>. To get more help on it, type <code><a href="../reference/md_series_lifetime.html">?md_series_lifetime</a></code>.</p>
<div class="section level3">
<h3 id="candidate-sets">Candidate sets<a class="anchor" aria-label="anchor" href="#candidate-sets"></a>
</h3>
<p>We simulate candidate sets using the Bernoulli candidate model with an appropriate set of parameters to satisfy conditions <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span>:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">md</span> <span class="op">&lt;-</span> <span class="va">md</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="../reference/md_bernoulli_candidate_C1_C2_C3.html">md_bernoulli_candidate_C1_C2_C3</a></span><span class="op">(</span><span class="va">m</span>, <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">.5</span>,<span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">md</span><span class="op">)</span>
<span class="co">#&gt; <span style="color: #949494;"># A tibble: 300 × 8</span></span>
<span class="co">#&gt;        t1    t2     t3     k      t x1    x2    x3   </span>
<span class="co">#&gt;     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;lgl&gt;</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 0.046<span style="text-decoration: underline;">5</span> 0.321 0.170      1 0.046<span style="text-decoration: underline;">5</span> TRUE  TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 1.03   0.678 0.205      3 0.205  FALSE FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 0.604  0.200 0.627      2 0.200  FALSE TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 0.090<span style="text-decoration: underline;">3</span> 1.08  0.320      1 0.090<span style="text-decoration: underline;">3</span> TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 0.150  0.210 0.415      1 0.150  TRUE  FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 0.224  0.188 0.439      2 0.188  TRUE  TRUE  FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 0.717  0.468 0.035<span style="text-decoration: underline;">1</span>     3 0.035<span style="text-decoration: underline;">1</span> TRUE  TRUE  TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 0.099<span style="text-decoration: underline;">6</span> 0.136 0.116      1 0.099<span style="text-decoration: underline;">6</span> TRUE  FALSE FALSE</span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 0.284  0.223 0.107      3 0.107  FALSE FALSE TRUE </span>
<span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 0.118  0.654 1.07       1 0.118  TRUE  FALSE FALSE</span>
<span class="co">#&gt; <span style="color: #949494;"># … with 290 more rows</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="log-likelihood-of-theta-given-masked-data">Log-likelihood of <span class="math inline">\(\theta\)</span> given masked data<a class="anchor" aria-label="anchor" href="#log-likelihood-of-theta-given-masked-data"></a>
</h3>
<p>The reduced log-likelihood function (the log of the kernel of the likelihood function) is given by <span class="math display">\[
\ell(\theta) =
    -\left(\sum_{i=1}^{n} t_i\right)
    \left(\sum_{j=1}^{m} \theta_j\right) +
    \sum_{i=1}^{n} \log\left(\sum_{j \in c_i} \theta_j\right).
\]</span></p>
<p>The following log-likelihood constructor, <code>md_loglike_exp_series_C1_C2_c3</code>, is implemented using minimally sufficient statistics, which significantly improves the computational efficiency of computing the log-likelihood.</p>
<p>We compute the log-likelihood function as a function of the masked data <code>md</code> with:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">l</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/md_loglike_exp_series_C1_C2_C3.html">md_loglike_exp_series_C1_C2_C3</a></span><span class="op">(</span><span class="va">md</span><span class="op">)</span></code></pre></div>
<p>The log-likelihood function contains the maximum amount of information about parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> given the sample of masked data <code>md</code> satisfying conditions <span class="math inline">\(C_1\)</span>, <span class="math inline">\(C_2\)</span>, and <span class="math inline">\(C_3\)</span>.</p>
<p>Suppose we do not know that <span class="math inline">\(\boldsymbol{\theta }= (3,4,5)'\)</span>. With the log-likelihood, we may estimate <span class="math inline">\(\theta\)</span> with <span class="math inline">\(\hat\theta\)</span> by solving <span class="math display">\[
\hat{\boldsymbol{\theta}} = \operatorname{argmax}_{\boldsymbol{\theta }\in \Omega} \ell(\theta),
\]</span> i.e., finding the point that <em>maximizes</em> the log-likelihood on the observed sample <code>md</code>. This is known as <em>maximum likelihood estimation</em> (MLE). We typically solve for the MLE by solving <span class="math display">\[
\nabla \ell|_{\boldsymbol{\theta}=\hat{\boldsymbol{\theta}}} = \boldsymbol{0}.
\]</span> We use the iterative method known as the gradient ascent to solve this, <span class="math display">\[
\boldsymbol{\theta}^{(n+1)} = \boldsymbol{\theta}^n + \alpha_n \nabla \ell(\boldsymbol{\theta}^n),
\]</span> where <span class="math inline">\(\alpha_n\)</span> is chosen to approximately maximize <span class="math inline">\(\ell(\theta^{(n+1))}\)</span> by using backtracking line search.</p>
<p>The function <code>md_mle_exp_series_C1_C2_C3</code> is a small wrapper for this function, providing <code>mle_gradient_ascent</code> with the appropriate arguments. We find <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> by running the following R code:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/md_mle_exp_series_C1_C2_C3.html">md_mle_exp_series_C1_C2_C3</a></span><span class="op">(</span><span class="va">md</span>,theta0<span class="op">=</span><span class="va">theta</span><span class="op">)</span>
<span class="va">theta.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/point.html" class="external-link">point</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span>
<span class="co">#&gt; Maximum likelihood estimator, of type mle_numerical ,</span>
<span class="co">#&gt; is normally distributed with mean</span>
<span class="co">#&gt; [1] 2.82 3.02 2.98</span>
<span class="co">#&gt; and variance-covariance</span>
<span class="co">#&gt;         [,1]    [,2]    [,3]</span>
<span class="co">#&gt; [1,]  0.1843 -0.0495 -0.0518</span>
<span class="co">#&gt; [2,] -0.0495  0.1926 -0.0542</span>
<span class="co">#&gt; [3,] -0.0518 -0.0542  0.1937</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; The asymptotic mean squared error 0.571 </span>
<span class="co">#&gt; The asymptotic 95% confidence interval is</span>
<span class="co">#&gt;   2.5 % 97.5 %</span>
<span class="co">#&gt; 1  2.11   3.53</span>
<span class="co">#&gt; 2  2.30   3.74</span>
<span class="co">#&gt; 3  2.26   3.71</span>
<span class="co">#&gt; The log-likelihood is 214 </span>
<span class="co">#&gt; The AIC is -423</span></code></pre></div>
<p>The function <code>md_mle_exp_series_C1_C2_C3</code> returns an <code>md_mle</code> object, which has various methods implemented for it, e.g., <code>confint</code> (computes the estimators confidence interval). In the above, we see use of the <code>summary</code> method, which takes an <code>mle</code> object and prints out a summary of its properties. We let <code>theta.hat</code> be given by the <code>point</code> method, which obtains the <em>best</em> the MLE <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>.</p>
<p>We see that <span class="math inline">\(\hat{\boldsymbol{\theta}} = (2.82, 3.023, 2.983)\)</span>. If we let the third argument in the log-likelihood function be fixed at <span class="math inline">\(\hat\theta_3 = 2.983)\)</span>, then we may profile the log-likelihood function over the first two parameters:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">prof</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta1</span><span class="op">)</span> <span class="op">{</span> <span class="fu">l</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">theta1</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">}</span>
<span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">-</span><span class="fl">2</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">+</span><span class="fl">2</span>,<span class="fl">.05</span><span class="op">)</span><span class="op">)</span>
<span class="va">data</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>
    <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">prof</span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span>
<span class="va">data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="fu">prof</span><span class="op">(</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="exponential_files/figure-html/unnamed-chunk-8-1.png" width="700"></p>
<p>Due to sampling variability, different runs of the experiment will result in different outcomes, i.e., <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> has a sampling distribution. We see that <span class="math inline">\(\hat{\boldsymbol{\theta}} \neq \boldsymbol{\theta}\)</span>, but it is reasonably close. We may measure this sampling variability using the variance-covariance matrix, bias, mean squared error (MSE), and confidence intervals.</p>
</div>
<div class="section level3">
<h3 id="sampling-distribution-of-the-mle">Sampling distribution of the MLE<a class="anchor" aria-label="anchor" href="#sampling-distribution-of-the-mle"></a>
</h3>
<p>The MLE <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> as a function of a random sample of masked data, and is thus a random vector. Theoretically, <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> converges in distribution to the multivariate normal with a mean <span class="math inline">\(\boldsymbol{\theta}\)</span> and we may estimate the variance-covariance with the inverse of the observed Fisher matrix, which is given by <span class="math display">\[
    J(\hat{\boldsymbol{\theta}}) = -\nabla^2 l|_{\hat{\boldsymbol{\theta}}}.
\]</span> Thus, <span class="math display">\[
    \hat{\boldsymbol{\theta}} \sim \mathcal{N}(\boldsymbol{\theta},J^{-1}(\hat{\boldsymbol{\theta}})).
\]</span></p>
<p>Asymptotically, <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> is the UMVUE, i.e., it is unbiased and obtains the minimum sampling variance. An estimate of the variance-covariance may be obtained with:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">V.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<table class="table"><tbody>
<tr class="odd">
<td align="right">0.184</td>
<td align="right">-0.050</td>
<td align="right">-0.052</td>
</tr>
<tr class="even">
<td align="right">-0.050</td>
<td align="right">0.193</td>
<td align="right">-0.054</td>
</tr>
<tr class="odd">
<td align="right">-0.052</td>
<td align="right">-0.054</td>
<td align="right">0.194</td>
</tr>
</tbody></table>
</div>
<div class="section level3">
<h3 id="bias-and-mean-squared-error">Bias and mean squared error<a class="anchor" aria-label="anchor" href="#bias-and-mean-squared-error"></a>
</h3>
<p>We would like to measure the accuracy and precision of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. In statistical literature, the bias <span class="math display">\[
\operatorname{b}(\hat{\boldsymbol{\theta}}) = E(\hat{\boldsymbol{\theta}}) - \boldsymbol{\theta}
\]</span> is a measure of accuracy and variance is a measure of precision.</p>
<p>The mean squared error, denoted by <span class="math inline">\(\operatorname{MSE}\)</span>, is a measure of estimator error that incorporates both the bias and the variance, <span class="math display">\[
\operatorname{MSE}(\hat{\boldsymbol{\theta}}) =
    \operatorname{trace}\bigl(\operatorname{vcov}(\hat{\boldsymbol{\theta}})\bigr) +
    \operatorname{b}^2(\hat{\boldsymbol{\theta}}).
\]</span></p>
<p>Since <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> is asymptotically unbiased and minimum variance, <span class="math display">\[
\lim_{n \to \infty} \operatorname{MSE}(\hat{\boldsymbol{\theta}}) =
    \operatorname{trace}\bigl(\operatorname{vcov}(\hat{\boldsymbol{\theta}})\bigr).
\]</span> Thus, for sufficiently large samples, <span class="math inline">\(\operatorname{MSE}(\hat{\boldsymbol{\theta}})\)</span> is approximately given by the <code>trace</code> of the estimated variance-covariance matrix:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">mse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">V.hat</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.571</span></code></pre></div>
<p>If we have a sample of <span class="math inline">\(n\)</span> MLEs, <span class="math inline">\(\hat{\boldsymbol{\theta}}^{(1)},\ldots,\hat{\boldsymbol{\theta}}^{(n)}\)</span>, then we may estimate both the bias and the MSE respectively with the statistics <span class="math display">\[
\hat{\operatorname{b}} = \frac{1}{n} \sum_{i=1} \hat{\boldsymbol{\theta}}^{(i)} - \boldsymbol{\theta}
\]</span> and <span class="math display">\[
\widehat{\operatorname{MSE}} = \frac{1}{n}
    \sum_{i=1}^n (\hat{\boldsymbol{\theta}}^{(i)} - \boldsymbol{\theta})
                 (\hat{\boldsymbol{\theta}}^{(i)} - \boldsymbol{\theta})'.
\]</span> We may then compare these statistics, <span class="math inline">\(\hat{\operatorname{b}}\)</span> and <span class="math inline">\(\widehat{\operatorname{MSE}}\)</span>, with the asymptotic bias <span class="math inline">\((\boldsymbol{0})\)</span> and the asymptotic <span class="math inline">\(\operatorname{MSE}\)</span>.</p>
<p>Let us compute estimates of the bias and mean squared error as a function of sample size <span class="math inline">\(n\)</span>:</p>
<p><img src="exponential_files/figure-html/unnamed-chunk-11-1.png" width="480"></p>
<p>A primary statistic is the <em>confidence interval</em>. A <span class="math inline">\((1-\alpha)100\%\)</span> confidence interval for <span class="math inline">\(\theta_j\)</span> may be estimated with <span class="math inline">\(\hat\theta_j \pm z_{1-\alpha/2} \sqrt{\hat{V}_{j j}}\)</span>. We provide a method for doing this calculation:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">2.5 %</th>
<th align="right">97.5 %</th>
<th align="right">length</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">2.11</td>
<td align="right">3.53</td>
<td align="right">1.41</td>
</tr>
<tr class="even">
<td align="right">2.30</td>
<td align="right">3.75</td>
<td align="right">1.44</td>
</tr>
<tr class="odd">
<td align="right">2.26</td>
<td align="right">3.71</td>
<td align="right">1.45</td>
</tr>
</tbody>
</table>
<p>How does this compare to the confidence intervals given that the candidate sets are generated using the Bernoulli candidate model with a different choice of parameters? First, we generate a new MLE using a different sample of masked data, <code>new.md</code>:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">new.md</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>
    t1<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span>n<span class="op">=</span><span class="va">n</span>,rate<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,
    t2<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span>n<span class="op">=</span><span class="va">n</span>,rate<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,
    t3<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html" class="external-link">rexp</a></span><span class="op">(</span>n<span class="op">=</span><span class="va">n</span>,rate<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="../reference/md_series_lifetime.html">md_series_lifetime</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="../reference/md_bernoulli_candidate_C1_C2_C3.html">md_bernoulli_candidate_C1_C2_C3</a></span><span class="op">(</span>m<span class="op">=</span><span class="fl">3</span>,p<span class="op">=</span><span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">.5</span>,<span class="va">n</span><span class="op">)</span><span class="op">)</span>
<span class="va">mle.new</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/md_mle_exp_series_C1_C2_C3.html">md_mle_exp_series_C1_C2_C3</a></span><span class="op">(</span><span class="va">new.md</span>,<span class="va">theta</span><span class="op">)</span></code></pre></div>
<p>Let’s compare the lengths of the confidence intervals:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">2.5 %</th>
<th align="right">97.5 %</th>
<th align="right">length</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">2.11</td>
<td align="right">3.53</td>
<td align="right">1.41</td>
</tr>
<tr class="even">
<td align="right">2.30</td>
<td align="right">3.75</td>
<td align="right">1.44</td>
</tr>
<tr class="odd">
<td align="right">2.26</td>
<td align="right">3.71</td>
<td align="right">1.45</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mle.new</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">2.5 %</th>
<th align="right">97.5 %</th>
<th align="right">length</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">2.24</td>
<td align="right">3.70</td>
<td align="right">1.46</td>
</tr>
<tr class="even">
<td align="right">2.25</td>
<td align="right">3.70</td>
<td align="right">1.45</td>
</tr>
<tr class="odd">
<td align="right">2.22</td>
<td align="right">3.72</td>
<td align="right">1.50</td>
</tr>
</tbody>
</table>
<p>We see that the lengths of the confidence intervals are significantly shorter.</p>
<p>If <em>no</em> information is provided about the component cause of failure in a series system with <span class="math inline">\(m\)</span> components, then the <span class="math inline">\(m_0\)</span> estimator is not unique and does not converge to <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<div class="section level4">
<h4 id="sampling-distribution-of-the-mle-1">Sampling distribution of the MLE<a class="anchor" aria-label="anchor" href="#sampling-distribution-of-the-mle-1"></a>
</h4>
<p>We know that <span class="math display">\[
\hat{\boldsymbol{\theta}} \sim \mathcal{N}\bigl(\boldsymbol{\theta},J^{-1}(\boldsymbol{\theta})\bigr).
\]</span> We can estimate the sampling distribution of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> with <span class="math inline">\(\mathcal{N}\bigl(\hat\theta,J^{-1}(\hat{\boldsymbol{\theta}})\bigr)\)</span>. This makes it trivial to estimate any other function of <span class="math inline">\(\boldsymbol{\theta}\)</span> by sampling from the approximation:</p>
<p>In Figure 2, we show contour plots of the first two components for the MLE sample.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="estimating-component-cause">Estimating component cause<a class="anchor" aria-label="anchor" href="#estimating-component-cause"></a>
</h2>
<p>Another characteristic we may wish to estimate is the probability that a particular component in an observation caused the system failure.</p>
<p>We wish to use as much information as possible to do this estimation. We consider three cases:</p>
<ol style="list-style-type: decimal">
<li><p>We have masked data <code>md</code> with candidate sets and system failure times and seek to estimate the node failure probabilities of observations in this data. This case provides the most accurate estimates of the node probability failures, as have both system failure times and candidate sets as predictors of the node failure.</p></li>
<li><p>We have a new observation of a system failure time and an estimate of <span class="math inline">\(\theta\)</span> from <code>md</code>. In this case, we cannot condition on candidate sets, since the observation does not include that information. However, we do have a system failure time.</p></li>
<li><p>We have an estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span> from <code>md</code> but wish to predict the node failure of a system that has failed, but we do not know when it failed.</p></li>
</ol>
<p>We consider case 1 described above where we have masked data <code>md</code> that includes both candidate sets and system failure times.</p>
<p>In this case, we are interested in <span class="math display">\[
    f_{K_i|C_i,T_i}(j|c_i,t_i,\boldsymbol{\theta}) = \frac{h_j(t;\boldsymbol{\theta_k})}{\sum_{j' \in c_i} h_{j'}(t_i;\boldsymbol{\theta_{j'}})},
\]</span> which in the exponential series case simplifies to <span class="math display">\[
    f_{K_i|C_,T_i}(j|c_i,t_i,\boldsymbol{\theta}) = \frac{\boldsymbol{\theta_j}}{\sum_{j' \in c_i} \boldsymbol{\theta_{j'}}}.
\]</span></p>
<p>We decorate <code>md</code> with this probability distribution with the decorator function <code>md_series_component_failure_probability</code>, which accepts masked data as input and returns the masked data with columns for component cause of failure probabilities given by <code>k1</code>,…,<code>km</code>.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#h &lt;- list(function(t) theta.hat[1],</span>
<span class="co">#          function(t) theta.hat[2],</span>
<span class="co">#          function(t) theta.hat[3])</span>
<span class="co">#md %&gt;% md_series_component_failure_probability_decorator(h)</span></code></pre></div>
<p>We notice that every row over the columns <code>k1</code>, <code>k2</code>, and <code>k3</code> given a specific candidate set are the same. This is as expected, since in the case of the exponential series, the component failure rates are constant with respect to system failure time.</p>
<p>If we already had an estimate of <span class="math inline">\(\boldsymbol{\theta}\)</span> and we sought to predict the failed components from only system lifetime data, we would just let the candidate sets contain all of the component indexes.</p>
<p>Also, observe that the component failure probabilities <span class="math display">\[
    \hat{\boldsymbol{k}}_i(\boldsymbol{\theta}) = (\hat{k}_1,\hat{k}_2,\hat{k}_3)'
\]</span> is a random vector whose sampling distribution under the right conditions is a multivariate normal whose <span class="math inline">\(j\)</span> component is given by <span class="math display">\[
    \hat{k}_j \sim \mathcal{N}(f_{K_i|T_i}(j|t_i,\boldsymbol{\theta}),\boldsymbol{\Sigma}_i).
\]</span> We can simulate <span class="math inline">\(n\)</span> draws from <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> and then apply the above statistic of interest, generating the data <span class="math display">\[
    \hat{\boldsymbol{k}}^{(1)},\ldots,\hat{\boldsymbol{k}}^{(n)}.
\]</span></p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Alexander Towell.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.3.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
